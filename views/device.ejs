<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Voice Control - <%= deviceId %></title>
  <style>
    * { margin: 0; padding: 0; box-sizing: border-box; }
    body {
      font-family: 'Segoe UI', Arial, sans-serif;
      background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
      min-height: 100vh;
      padding: 20px;
    }
    .container {
      max-width: 500px;
      margin: 0 auto;
    }
    .card {
      background: white;
      border-radius: 20px;
      box-shadow: 0 20px 60px rgba(0,0,0,0.3);
      padding: 30px;
      margin-bottom: 20px;
    }
    h1 {
      color: #667eea;
      text-align: center;
      margin-bottom: 10px;
      font-size: 28px;
    }
    .device-id {
      text-align: center;
      color: #666;
      margin-bottom: 20px;
      font-size: 14px;
      font-family: monospace;
    }
    .status-badge {
      display: inline-block;
      padding: 8px 16px;
      border-radius: 20px;
      font-size: 12px;
      font-weight: 600;
      margin-bottom: 20px;
    }
    .status-ready {
      background: #d1fae5;
      color: #065f46;
    }
    .status-recording {
      background: #fee2e2;
      color: #991b1b;
    }
    .status-processing {
      background: #fef3c7;
      color: #92400e;
    }
    select {
      transition: border-color 0.3s;
    }
    select:hover {
      border-color: #667eea;
    }
    select:focus {
      outline: none;
      border-color: #667eea;
      box-shadow: 0 0 0 3px rgba(102, 126, 234, 0.1);
    }
    .record-btn {
      width: 100%;
      padding: 60px 20px;
      background: linear-gradient(135deg, #3498db 0%, #2980b9 100%);
      color: white;
      border: none;
      border-radius: 20px;
      font-size: 24px;
      font-weight: 600;
      cursor: pointer;
      transition: all 0.3s;
      margin-bottom: 15px;
      user-select: none;
    }
    .record-btn:hover {
      transform: scale(1.02);
      box-shadow: 0 10px 30px rgba(52, 152, 219, 0.3);
    }
    .record-btn.recording {
      background: linear-gradient(135deg, #e74c3c 0%, #c0392b 100%);
      animation: pulse 1s infinite;
    }
    @keyframes pulse {
      0%, 100% { transform: scale(1); }
      50% { transform: scale(1.05); }
    }
    .instruction {
      text-align: center;
      color: #666;
      font-size: 14px;
      margin-bottom: 20px;
    }
    .result-box {
      background: #f8f9fa;
      padding: 20px;
      border-radius: 15px;
      margin-top: 20px;
      display: none;
    }
    .result-box.show {
      display: block;
    }
    .result-box.triggered {
      background: #fee2e2;
      border: 2px solid #ef4444;
    }
    .result-box.success {
      background: #d1fae5;
      border: 2px solid #10b981;
    }
    .result-title {
      font-weight: 600;
      margin-bottom: 10px;
      font-size: 16px;
    }
    .result-text {
      font-family: monospace;
      font-size: 14px;
      word-wrap: break-word;
    }
    .trigger-words {
      background: #f0f0f0;
      padding: 15px;
      border-radius: 10px;
      margin-bottom: 20px;
    }
    .trigger-words strong {
      color: #667eea;
      display: block;
      margin-bottom: 8px;
    }
    .back-link {
      display: block;
      text-align: center;
      color: white;
      text-decoration: none;
      margin-top: 20px;
      font-size: 14px;
    }
  </style>
</head>
<body>
  <div class="container">
    <div class="card">
      <h1>üéôÔ∏è Voice Control</h1>
      <div class="device-id">Device: <strong><%= deviceId %></strong></div>
      
      <div style="text-align: center; margin-bottom: 20px;">
        <span class="status-badge status-ready" id="statusBadge">Ready</span>
        <span class="status-badge" id="vadBadge" style="display: none; background: #e0e7ff; color: #3730a3; margin-left: 10px;">
          ü§ê Listening...
        </span>
      </div>
      
      <div style="margin-bottom: 20px;">
        <label style="display: block; margin-bottom: 8px; color: #333; font-weight: 600; font-size: 14px;">
          ü§ñ Speech Recognition API
        </label>
        <select id="apiSelector" style="width: 100%; padding: 12px; border: 2px solid #e0e0e0; border-radius: 8px; font-size: 14px; background: white; cursor: pointer;">
          <option value="assemblyai">AssemblyAI</option>
          <option value="deepgram">Deepgram</option>
        </select>
      </div>
      
      <div style="background: #e0f2fe; padding: 12px; border-radius: 10px; margin-bottom: 20px; font-size: 13px; border-left: 4px solid #0ea5e9;">
        <strong style="color: #075985;">üí° Voice Detection Active:</strong>
        <ul style="margin: 8px 0 0 20px; color: #0c4a6e;">
          <li>Only processes when voice is detected</li>
          <li>3-second recording chunks when speaking</li>
          <li>Skips silent periods (saves bandwidth)</li>
          <li>Real-time audio level indicator</li>
        </ul>
      </div>
      
      <button id="recordBtn" class="record-btn">
        üéôÔ∏è<br>Start Continuous Monitoring
      </button>
      
      <div class="instruction" id="instruction">
        Click to start/stop continuous voice monitoring
      </div>
      
      <div style="text-align: center; margin-bottom: 15px; display: none;" id="audioLevel">
        <div style="background: #f0f0f0; height: 20px; border-radius: 10px; overflow: hidden;">
          <div id="levelBar" style="background: linear-gradient(90deg, #10b981, #3b82f6); height: 100%; width: 0%; transition: width 0.1s;"></div>
        </div>
        <small style="color: #666; font-size: 12px;">Audio Level</small>
      </div>
      
      <div id="resultBox" class="result-box">
        <div class="result-title" id="resultTitle">Result</div>
        <div class="result-text" id="resultText"></div>
      </div>
    </div>
    
    <a href="/" class="back-link">‚Üê Back to Home</a>
  </div>

  <script>
    const deviceId = '<%= deviceId %>';
    let mediaRecorder;
    let audioChunks = [];
    let isRecording = false;
    let isContinuousMode = false;
    let audioContext;
    let analyser;
    let microphone;
    let recordingStartTime;
    const RECORDING_DURATION = 3000; // Record for 3 seconds at a time
    const VOICE_THRESHOLD = 2; // Minimum audio level to detect voice (lowered from 5 to 2 for better sensitivity)
    const SILENCE_DURATION = 800; // ms of silence before considering no voice (reduced for faster response)
    let lastVoiceTime = 0;
    let isVoiceDetected = false;
    
    const recordBtn = document.getElementById('recordBtn');
    const statusBadge = document.getElementById('statusBadge');
    const instruction = document.getElementById('instruction');
    const resultBox = document.getElementById('resultBox');
    const resultTitle = document.getElementById('resultTitle');
    const resultText = document.getElementById('resultText');
    const audioLevelDiv = document.getElementById('audioLevel');
    const levelBar = document.getElementById('levelBar');
    const vadBadge = document.getElementById('vadBadge');
    
    async function initMicrophone() {
      try {
        const stream = await navigator.mediaDevices.getUserMedia({ 
          audio: {
            channelCount: 1,
            sampleRate: 16000,
            echoCancellation: true,
            noiseSuppression: true,
            autoGainControl: true
          } 
        });
        
        // Setup audio context for level monitoring
        audioContext = new (window.AudioContext || window.webkitAudioContext)();
        analyser = audioContext.createAnalyser();
        microphone = audioContext.createMediaStreamSource(stream);
        microphone.connect(analyser);
        analyser.fftSize = 256;
        
        console.log('üé§ Microphone initialized');
        console.log('Sample rate:', audioContext.sampleRate);
        
        // Use WebM format if supported, otherwise use default
        const options = { mimeType: 'audio/webm;codecs=opus' };
        
        try {
          mediaRecorder = new MediaRecorder(stream, options);
        } catch (e) {
          console.log('WebM not supported, trying default format');
          mediaRecorder = new MediaRecorder(stream);
        }
        
        console.log('üì± Using format:', mediaRecorder.mimeType);
        
        mediaRecorder.ondataavailable = (event) => {
          if (event.data.size > 0) {
            audioChunks.push(event.data);
            console.log('üì¶ Audio chunk:', event.data.size, 'bytes');
          }
        };
        
        mediaRecorder.onstop = async () => {
          const recordingDuration = Date.now() - recordingStartTime;
          console.log('‚è±Ô∏è Recording duration:', recordingDuration, 'ms');
          console.log('üì¶ Total chunks:', audioChunks.length);
          
          if (audioChunks.length === 0) {
            showError('No audio data captured. Please try again.');
            return;
          }
          
          const audioBlob = new Blob(audioChunks, { type: mediaRecorder.mimeType });
          console.log('üì¶ Final blob size:', audioBlob.size, 'bytes');
          audioChunks = [];
          
          if (recordingDuration < 500) {
            showError('Recording too short. Hold button for at least 1 second.');
            return;
          }
          
          await processAudio(audioBlob);
        };
        
        return true;
      } catch (e) {
        console.error('Microphone error:', e);
        alert('Microphone access denied. Please allow microphone access and refresh.');
        return false;
      }
    }
    
    async function processAudio(audioBlob) {
      statusBadge.textContent = 'Processing...';
      statusBadge.className = 'status-badge status-processing';
      instruction.textContent = 'Analyzing your voice command...';
      
      const selectedAPI = document.getElementById('apiSelector').value;
      
      console.log('üì§ Sending audio:', {
        size: audioBlob.size,
        type: audioBlob.type,
        deviceId: deviceId,
        api: selectedAPI
      });
      
      try {
        const res = await fetch('/api/process-audio', {
          method: 'POST',
          headers: { 
            'Content-Type': audioBlob.type || 'audio/webm',
            'X-Device-ID': deviceId,
            'X-Speech-API': selectedAPI
          },
          body: audioBlob
        });
        
        const data = await res.json();
        console.log('üì• Received response:', data);
        
        if (data.success) {
          showResult(data);
        } else {
          showError('Failed to process audio: ' + (data.error || 'Unknown error'));
        }
        
        // If in continuous mode, restart recording
        if (isContinuousMode) {
          setTimeout(() => {
            if (isContinuousMode) {
              startRecordingCycle();
            }
          }, 500); // Small delay before next cycle
        }
      } catch (e) {
        console.error('‚ùå Error:', e);
        showError('Error sending audio: ' + e.message);
        
        // Retry in continuous mode
        if (isContinuousMode) {
          setTimeout(() => {
            if (isContinuousMode) {
              startRecordingCycle();
            }
          }, 2000);
        }
      }
      
      if (!isContinuousMode) {
        statusBadge.textContent = 'Ready';
        statusBadge.className = 'status-badge status-ready';
        instruction.textContent = 'Click to start/stop continuous voice monitoring';
      }
    }
    
    function showResult(data) {
      console.log('üìä Result:', data);
      
      resultTitle.textContent = data.triggered ? 'üö® ALARM TRIGGERED!' : '‚úì Voice Recognized';
      resultText.innerHTML = `
        <strong>Transcription:</strong> ${data.transcription || '(listening...)'}<br>
        <strong>Confidence:</strong> ${(data.confidence * 100).toFixed(1)}%<br>
        <strong>API Used:</strong> ${data.speechAPI || 'unknown'}<br>
        <strong>Triggered:</strong> ${data.triggered ? 'YES' : 'NO'}
        ${data.triggered ? '<br><strong>Words:</strong> ' + data.triggeredWords.join(', ') : ''}
        ${data.processingTime ? '<br><strong>Processing Time:</strong> ' + data.processingTime + 'ms' : ''}
      `;
      
      resultBox.className = 'result-box show ' + (data.triggered ? 'triggered' : 'success');
    }
    
    function showError(message) {
      resultTitle.textContent = '‚ùå Error';
      resultText.textContent = message;
      resultBox.className = 'result-box show';
    }
    
    async function startRecording() {
      if (!mediaRecorder) {
        const success = await initMicrophone();
        if (!success) return;
      }
      
      if (!isContinuousMode) {
        // Start continuous monitoring mode
        isContinuousMode = true;
        recordBtn.textContent = '‚èπÔ∏è\nStop Monitoring';
        recordBtn.classList.add('recording');
        statusBadge.textContent = 'Continuous Monitoring';
        statusBadge.className = 'status-badge status-recording';
        instruction.textContent = 'Listening continuously... Speak naturally';
        audioLevelDiv.style.display = 'block';
        vadBadge.style.display = 'inline-block';
        
        console.log('üéôÔ∏è Started continuous monitoring mode');
        
        // Initialize voice detection
        lastVoiceTime = Date.now();
        startRecordingCycle();
      } else {
        // Stop continuous mode
        stopContinuousMode();
      }
    }
    
    function startRecordingCycle() {
      if (!isContinuousMode) return;
      
      // More sensitive - record if voice detected or recently detected
      const timeSinceLastVoice = Date.now() - lastVoiceTime;
      const shouldRecord = isVoiceDetected || timeSinceLastVoice < (SILENCE_DURATION * 2) || lastVoiceTime === 0;
      
      if (!shouldRecord) {
        console.log('‚è≠Ô∏è Skipping recording - no voice (last:', (timeSinceLastVoice / 1000).toFixed(1), 's ago)');
        // Check again soon
        setTimeout(() => {
          if (isContinuousMode) {
            startRecordingCycle();
          }
        }, 300); // Check more frequently
        return;
      }
      
      audioChunks = [];
      recordingStartTime = Date.now();
      
      if (mediaRecorder.state === 'inactive') {
        console.log('üéôÔ∏è Starting recording cycle (voice level check passed)');
        mediaRecorder.start(100);
        isRecording = true;
        
        // Monitor audio levels
        monitorAudioLevel();
        
        // Auto-stop after RECORDING_DURATION
        setTimeout(() => {
          if (isRecording && isContinuousMode) {
            mediaRecorder.stop();
            isRecording = false;
          }
        }, RECORDING_DURATION);
      }
    }
    
    function monitorAudioLevel() {
      if (!isRecording || !analyser) return;
      
      const dataArray = new Uint8Array(analyser.frequencyBinCount);
      analyser.getByteFrequencyData(dataArray);
      
      const average = dataArray.reduce((a, b) => a + b) / dataArray.length;
      const percentage = Math.min(100, (average / 128) * 100);
      
      // Update visual indicator
      levelBar.style.width = percentage + '%';
      
      // Voice Activity Detection
      if (average > VOICE_THRESHOLD) {
        lastVoiceTime = Date.now();
        if (!isVoiceDetected) {
          isVoiceDetected = true;
          console.log('üó£Ô∏è Voice detected! Level:', average.toFixed(1), '(threshold:', VOICE_THRESHOLD + ')');
          vadBadge.textContent = 'üó£Ô∏è Voice Detected';
          vadBadge.style.background = '#fee2e2';
          vadBadge.style.color = '#991b1b';
          levelBar.style.background = 'linear-gradient(90deg, #ef4444, #dc2626)';
        }
      } else {
        // Check if silence duration exceeded
        if (isVoiceDetected && (Date.now() - lastVoiceTime) > SILENCE_DURATION) {
          isVoiceDetected = false;
          console.log('ü§ê Silence detected (below threshold:', VOICE_THRESHOLD + ')');
          vadBadge.textContent = 'ü§ê Listening...';
          vadBadge.style.background = '#e0e7ff';
          vadBadge.style.color = '#3730a3';
          levelBar.style.background = 'linear-gradient(90deg, #10b981, #3b82f6)';
        }
      }
      
      if (isRecording) {
        requestAnimationFrame(monitorAudioLevel);
      }
    }
    
    function stopRecording() {
      if (isRecording) {
        mediaRecorder.stop();
        isRecording = false;
        
        recordBtn.textContent = 'üéôÔ∏è\nHold to Record';
        recordBtn.classList.remove('recording');
        audioLevelDiv.style.display = 'none';
        levelBar.style.width = '0%';
      }
    }
    
    function stopContinuousMode() {
      isContinuousMode = false;
      isVoiceDetected = false;
      
      if (isRecording && mediaRecorder.state !== 'inactive') {
        mediaRecorder.stop();
        isRecording = false;
      }
      
      recordBtn.textContent = 'üéôÔ∏è\nStart Continuous Monitoring';
      recordBtn.classList.remove('recording');
      statusBadge.textContent = 'Ready';
      statusBadge.className = 'status-badge status-ready';
      instruction.textContent = 'Click to start/stop continuous voice monitoring';
      audioLevelDiv.style.display = 'none';
      vadBadge.style.display = 'none';
      levelBar.style.width = '0%';
      
      console.log('‚èπÔ∏è Stopped continuous monitoring');
    }
    
    // Click event (toggle continuous mode)
    recordBtn.addEventListener('click', startRecording);
  </script>
</body>
</html>
